{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "1b5435c8",
      "metadata": {
        "id": "1b5435c8"
      },
      "source": [
        "# World Happiness Report"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db2aa9ed",
      "metadata": {
        "id": "db2aa9ed"
      },
      "source": [
        "Happiness Prediction Deep Learning Solution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "31cca4e1",
      "metadata": {
        "id": "31cca4e1"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import torch.nn.init as init\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "18d80ef0",
      "metadata": {
        "id": "18d80ef0"
      },
      "source": [
        "## Create Column Mappings & Initialize Variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f55713a2",
      "metadata": {
        "id": "f55713a2"
      },
      "outputs": [],
      "source": [
        "data_frames = []\n",
        "common_columns = ['country', 'rank', 'score', 'gdp', 'family', 'health', 'freedom', 'corruption', 'generosity']\n",
        "column_mapping = {\n",
        "    '2015': {\n",
        "        'Country': 'country',\n",
        "        'Happiness Rank': 'rank',\n",
        "        'Happiness Score': 'score',\n",
        "        'Economy (GDP per Capita)': 'gdp',\n",
        "        'Family': 'family',\n",
        "        'Health (Life Expectancy)': 'health',\n",
        "        'Freedom': 'freedom',\n",
        "        'Trust (Government Corruption)': 'corruption',\n",
        "        'Generosity': 'generosity'\n",
        "    },\n",
        "    '2016': {\n",
        "        'Country': 'country',\n",
        "        'Happiness Rank': 'rank',\n",
        "        'Happiness Score': 'score',\n",
        "        'Economy (GDP per Capita)': 'gdp',\n",
        "        'Family': 'family',\n",
        "        'Health (Life Expectancy)': 'health',\n",
        "        'Freedom': 'freedom',\n",
        "        'Trust (Government Corruption)': 'corruption',\n",
        "        'Generosity': 'generosity'\n",
        "    },\n",
        "    '2017': {\n",
        "        'Country':'country',\n",
        "        'Happiness.Rank':'rank',\n",
        "        'Happiness.Score':'score',\n",
        "        'Economy..GDP.per.Capita.':'gdp',\n",
        "        'Family':'family',\n",
        "        'Health..Life.Expectancy.':'health',\n",
        "        'Freedom':'freedom',\n",
        "        'Generosity':'generosity',\n",
        "        'Trust..Government.Corruption.':'corruption'\n",
        "    },\n",
        "    '2018': {\n",
        "        'Country or region':'country',\n",
        "        'Overall rank':'rank',\n",
        "        'Score':'score',\n",
        "        'GDP per capita':'gdp',\n",
        "        'Social support':'family',\n",
        "        'Healthy life expectancy':'health',\n",
        "        'Freedom to make life choices':'freedom',\n",
        "        'Generosity':'generosity',\n",
        "        'Perceptions of corruption':'corruption'\n",
        "    },\n",
        "     '2019': {\n",
        "        'Country or region':'country',\n",
        "        'Overall rank':'rank',\n",
        "        'Score':'score',\n",
        "        'GDP per capita':'gdp',\n",
        "        'Social support':'family',\n",
        "        'Healthy life expectancy':'health',\n",
        "        'Freedom to make life choices':'freedom',\n",
        "        'Generosity':'generosity',\n",
        "        'Perceptions of corruption':'corruption'\n",
        "    }\n",
        "}\n",
        "\n",
        "years = ['2015', '2016','2017','2018','2019']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dd450bda",
      "metadata": {
        "id": "dd450bda"
      },
      "source": [
        "## Import Datasets and Map Columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e8fc8ddb",
      "metadata": {
        "id": "e8fc8ddb",
        "outputId": "eb75b759-eb29-4369-befd-bca9093d3eea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['country', 'rank', 'score', 'gdp', 'family', 'health', 'freedom', 'corruption', 'generosity']\n",
            "['country', 'rank', 'score', 'gdp', 'family', 'health', 'freedom', 'corruption', 'generosity']\n",
            "['country', 'rank', 'score', 'gdp', 'family', 'health', 'freedom', 'corruption', 'generosity']\n",
            "['country', 'rank', 'score', 'gdp', 'family', 'health', 'freedom', 'corruption', 'generosity']\n",
            "['country', 'rank', 'score', 'gdp', 'family', 'health', 'freedom', 'corruption', 'generosity']\n"
          ]
        }
      ],
      "source": [
        "for year in years:\n",
        "    file_path = f'./dataset/{year}.csv'\n",
        "    df = pd.read_csv(file_path)\n",
        "\n",
        "    # Rename columns to common names\n",
        "    df.rename(columns=column_mapping[year], inplace=True)\n",
        "\n",
        "    df = df[common_columns]\n",
        "\n",
        "    print(list(df.head()))\n",
        "\n",
        "    data_frames.append(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "33a0ceac",
      "metadata": {
        "id": "33a0ceac"
      },
      "source": [
        "## Merge Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "17c4d051",
      "metadata": {
        "id": "17c4d051",
        "outputId": "f536ec96-dddd-410b-ada1-3d7bf29c2ffc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 782 entries, 0 to 781\n",
            "Data columns (total 9 columns):\n",
            " #   Column      Non-Null Count  Dtype  \n",
            "---  ------      --------------  -----  \n",
            " 0   country     782 non-null    object \n",
            " 1   rank        782 non-null    int64  \n",
            " 2   score       782 non-null    float64\n",
            " 3   gdp         782 non-null    float64\n",
            " 4   family      782 non-null    float64\n",
            " 5   health      782 non-null    float64\n",
            " 6   freedom     782 non-null    float64\n",
            " 7   corruption  781 non-null    float64\n",
            " 8   generosity  782 non-null    float64\n",
            "dtypes: float64(7), int64(1), object(1)\n",
            "memory usage: 55.1+ KB\n",
            "None\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 781 entries, 0 to 781\n",
            "Data columns (total 9 columns):\n",
            " #   Column      Non-Null Count  Dtype  \n",
            "---  ------      --------------  -----  \n",
            " 0   country     781 non-null    object \n",
            " 1   rank        781 non-null    int64  \n",
            " 2   score       781 non-null    float64\n",
            " 3   gdp         781 non-null    float64\n",
            " 4   family      781 non-null    float64\n",
            " 5   health      781 non-null    float64\n",
            " 6   freedom     781 non-null    float64\n",
            " 7   corruption  781 non-null    float64\n",
            " 8   generosity  781 non-null    float64\n",
            "dtypes: float64(7), int64(1), object(1)\n",
            "memory usage: 61.0+ KB\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "merged_data = pd.concat(data_frames, ignore_index=True)\n",
        "print(merged_data.info())\n",
        "merged_data = merged_data.dropna()\n",
        "print(merged_data.info())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d321ff79",
      "metadata": {
        "id": "d321ff79"
      },
      "source": [
        "## Define Target and Training Columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b1c68a47",
      "metadata": {
        "id": "b1c68a47"
      },
      "outputs": [],
      "source": [
        "target_column = 'score'\n",
        "\n",
        "predictor_columns = [ 'gdp', 'family', 'health', 'freedom', 'generosity', 'corruption']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "90efb69b",
      "metadata": {
        "id": "90efb69b"
      },
      "source": [
        "## Split the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dddd453c",
      "metadata": {
        "id": "dddd453c"
      },
      "outputs": [],
      "source": [
        "# Split the data into training and testing sets\n",
        "X = merged_data[predictor_columns].values\n",
        "y = merged_data[target_column].values\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=69)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c3efa84c",
      "metadata": {
        "id": "c3efa84c"
      },
      "source": [
        "## Normalize data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e1821d54",
      "metadata": {
        "id": "e1821d54"
      },
      "source": [
        "A Min-Max Scaler was used to normalize the data to a range of 0 to 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22dec0b2",
      "metadata": {
        "id": "22dec0b2"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import RobustScaler\n",
        "\n",
        "# Create a RobustScaler instance\n",
        "scaler = RobustScaler()\n",
        "\n",
        "# Fit and transform the training data\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "\n",
        "# Transform the testing data using the same scaler\n",
        "X_test = scaler.transform(X_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0b72db49",
      "metadata": {
        "id": "0b72db49"
      },
      "source": [
        "## Convert data to Pythorch tensors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "483cf5e2",
      "metadata": {
        "id": "483cf5e2"
      },
      "outputs": [],
      "source": [
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b900b0c2",
      "metadata": {
        "id": "b900b0c2"
      },
      "source": [
        "## Define the Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "afb52f80",
      "metadata": {
        "id": "afb52f80"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.nn.init as init\n",
        "\n",
        "class HappinessPredictor(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super(ComplexHappinessPredictor, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, 256)\n",
        "        self.bn1 = nn.BatchNorm1d(256)\n",
        "        self.fc2 = nn.Linear(256, 128)\n",
        "        self.bn2 = nn.BatchNorm1d(128)\n",
        "        self.fc3 = nn.Linear(128, 64)\n",
        "        self.bn3 = nn.BatchNorm1d(64)\n",
        "        self.fc4 = nn.Linear(64, 32)\n",
        "        self.fc5 = nn.Linear(32, 1)\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "        # Initialize weights using Kaiming (He) initialization\n",
        "        init.kaiming_uniform_(self.fc1.weight, mode='fan_in', nonlinearity='relu')\n",
        "        init.kaiming_uniform_(self.fc2.weight, mode='fan_in', nonlinearity='relu')\n",
        "        init.kaiming_uniform_(self.fc3.weight, mode='fan_in', nonlinearity='relu')\n",
        "        init.kaiming_uniform_(self.fc4.weight, mode='fan_in', nonlinearity='relu')\n",
        "        init.kaiming_uniform_(self.fc5.weight, mode='fan_in')\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.bn1(self.fc1(x)))\n",
        "        x = self.dropout(x)\n",
        "        x = self.relu(self.bn2(self.fc2(x)))\n",
        "        x = self.dropout(x)\n",
        "        x = self.relu(self.bn3(self.fc3(x)))\n",
        "        x = self.dropout(x)\n",
        "        x = self.relu(self.fc4(x))\n",
        "        x = self.fc5(x)\n",
        "        return x\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c96ebe6c",
      "metadata": {
        "id": "c96ebe6c"
      },
      "source": [
        "## Loss Funcion & Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "094e1674",
      "metadata": {
        "id": "094e1674"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# Define the momentum factor\n",
        "momentum = 0.9\n",
        "\n",
        "# Define the learning rate\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Instantiate the model\n",
        "input_size = X_train_tensor.shape[1]\n",
        "model = HappinessPredictor(input_size)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.SmoothL1Loss() #Mean Absolute Error (MAE) Loss\n",
        "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum, weight_decay=1e-5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f6afd2d7",
      "metadata": {
        "id": "f6afd2d7"
      },
      "source": [
        "## Training the Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84957ef9",
      "metadata": {
        "id": "84957ef9",
        "outputId": "e7d16b54-470b-4788-bea3-e1d45b7b6bda"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [100/2000], Loss: 0.4090\n",
            "Epoch [200/2000], Loss: 0.2626\n",
            "Epoch [300/2000], Loss: 0.2139\n",
            "Epoch [400/2000], Loss: 0.1992\n",
            "Epoch [500/2000], Loss: 0.1737\n",
            "Epoch [600/2000], Loss: 0.1652\n",
            "Epoch [700/2000], Loss: 0.1680\n",
            "Epoch [800/2000], Loss: 0.1491\n",
            "Epoch [900/2000], Loss: 0.1362\n",
            "Epoch [1000/2000], Loss: 0.1323\n",
            "Epoch [1100/2000], Loss: 0.1304\n",
            "Epoch [1200/2000], Loss: 0.1232\n",
            "Epoch [1300/2000], Loss: 0.1188\n",
            "Epoch [1400/2000], Loss: 0.1187\n",
            "Epoch [1500/2000], Loss: 0.1098\n",
            "Epoch [1600/2000], Loss: 0.1018\n",
            "Epoch [1700/2000], Loss: 0.1009\n",
            "Epoch [1800/2000], Loss: 0.0957\n",
            "Epoch [1900/2000], Loss: 0.1018\n",
            "Epoch [2000/2000], Loss: 0.1065\n"
          ]
        }
      ],
      "source": [
        "num_epochs =6000\n",
        "for epoch in range(num_epochs):\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(X_train_tensor)\n",
        "    loss = criterion(outputs, y_train_tensor.view(-1, 1))\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (epoch + 1) % 100 == 0:\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "111a1c53",
      "metadata": {
        "id": "111a1c53"
      },
      "source": [
        "## Evaluate Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c2b1aa3",
      "metadata": {
        "id": "4c2b1aa3",
        "outputId": "a2639424-00fc-40ec-cc18-ed21ca35534d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean Squared Error on Test Data: 0.2604\n"
          ]
        }
      ],
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    test_outputs = model(X_test_tensor)\n",
        "\n",
        "mse = mean_squared_error(y_test_tensor.numpy(), test_outputs.numpy())\n",
        "print(f'Mean Squared Error on Test Data: {mse:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7aaba075",
      "metadata": {
        "id": "7aaba075"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}