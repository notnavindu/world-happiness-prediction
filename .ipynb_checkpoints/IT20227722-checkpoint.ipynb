{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b5435c8",
   "metadata": {},
   "source": [
    "# World Happiness Report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2aa9ed",
   "metadata": {},
   "source": [
    "Happiness Prediction Deep Learning Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31cca4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import torch.nn.init as init\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d80ef0",
   "metadata": {},
   "source": [
    "## Create Column Mappings & Initialize Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f55713a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frames = []\n",
    "common_columns = ['country', 'rank', 'score', 'gdp', 'family', 'health', 'freedom', 'corruption', 'generosity']\n",
    "column_mapping = {\n",
    "    '2015': {\n",
    "        'Country': 'country',\n",
    "        'Happiness Rank': 'rank',\n",
    "        'Happiness Score': 'score',\n",
    "        'Economy (GDP per Capita)': 'gdp',\n",
    "        'Family': 'family',\n",
    "        'Health (Life Expectancy)': 'health',\n",
    "        'Freedom': 'freedom',\n",
    "        'Trust (Government Corruption)': 'corruption',\n",
    "        'Generosity': 'generosity'\n",
    "    },\n",
    "    '2016': {\n",
    "        'Country': 'country',\n",
    "        'Happiness Rank': 'rank',\n",
    "        'Happiness Score': 'score',\n",
    "        'Economy (GDP per Capita)': 'gdp',\n",
    "        'Family': 'family',\n",
    "        'Health (Life Expectancy)': 'health',\n",
    "        'Freedom': 'freedom',\n",
    "        'Trust (Government Corruption)': 'corruption',\n",
    "        'Generosity': 'generosity'\n",
    "    },\n",
    "    '2017': {\n",
    "        'Country':'country',\n",
    "        'Happiness.Rank':'rank',\n",
    "        'Happiness.Score':'score',\n",
    "        'Economy..GDP.per.Capita.':'gdp',\n",
    "        'Family':'family',\n",
    "        'Health..Life.Expectancy.':'health',\n",
    "        'Freedom':'freedom',\n",
    "        'Generosity':'generosity',\n",
    "        'Trust..Government.Corruption.':'corruption'\n",
    "    },\n",
    "    '2018': {\n",
    "        'Country or region':'country',\n",
    "        'Overall rank':'rank',\n",
    "        'Score':'score',\n",
    "        'GDP per capita':'gdp',\n",
    "        'Social support':'family',\n",
    "        'Healthy life expectancy':'health',\n",
    "        'Freedom to make life choices':'freedom',\n",
    "        'Generosity':'generosity',\n",
    "        'Perceptions of corruption':'corruption'\n",
    "    },\n",
    "     '2019': {\n",
    "        'Country or region':'country',\n",
    "        'Overall rank':'rank',\n",
    "        'Score':'score',\n",
    "        'GDP per capita':'gdp',\n",
    "        'Social support':'family',\n",
    "        'Healthy life expectancy':'health',\n",
    "        'Freedom to make life choices':'freedom',\n",
    "        'Generosity':'generosity',\n",
    "        'Perceptions of corruption':'corruption'\n",
    "    }\n",
    "} \n",
    "\n",
    "years = ['2015', '2016','2017','2018','2019']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd450bda",
   "metadata": {},
   "source": [
    "## Import Datasets and Map Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8fc8ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['country', 'rank', 'score', 'gdp', 'family', 'health', 'freedom', 'corruption', 'generosity']\n",
      "['country', 'rank', 'score', 'gdp', 'family', 'health', 'freedom', 'corruption', 'generosity']\n",
      "['country', 'rank', 'score', 'gdp', 'family', 'health', 'freedom', 'corruption', 'generosity']\n",
      "['country', 'rank', 'score', 'gdp', 'family', 'health', 'freedom', 'corruption', 'generosity']\n",
      "['country', 'rank', 'score', 'gdp', 'family', 'health', 'freedom', 'corruption', 'generosity']\n"
     ]
    }
   ],
   "source": [
    "for year in years:\n",
    "    file_path = f'./dataset/{year}.csv'\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Rename columns to common names\n",
    "    df.rename(columns=column_mapping[year], inplace=True)\n",
    "    \n",
    "    df = df[common_columns]\n",
    "    \n",
    "    print(list(df.head()))\n",
    "    \n",
    "    data_frames.append(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a0ceac",
   "metadata": {},
   "source": [
    "## Merge Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17c4d051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 782 entries, 0 to 781\n",
      "Data columns (total 9 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   country     782 non-null    object \n",
      " 1   rank        782 non-null    int64  \n",
      " 2   score       782 non-null    float64\n",
      " 3   gdp         782 non-null    float64\n",
      " 4   family      782 non-null    float64\n",
      " 5   health      782 non-null    float64\n",
      " 6   freedom     782 non-null    float64\n",
      " 7   corruption  781 non-null    float64\n",
      " 8   generosity  782 non-null    float64\n",
      "dtypes: float64(7), int64(1), object(1)\n",
      "memory usage: 55.1+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 781 entries, 0 to 781\n",
      "Data columns (total 9 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   country     781 non-null    object \n",
      " 1   rank        781 non-null    int64  \n",
      " 2   score       781 non-null    float64\n",
      " 3   gdp         781 non-null    float64\n",
      " 4   family      781 non-null    float64\n",
      " 5   health      781 non-null    float64\n",
      " 6   freedom     781 non-null    float64\n",
      " 7   corruption  781 non-null    float64\n",
      " 8   generosity  781 non-null    float64\n",
      "dtypes: float64(7), int64(1), object(1)\n",
      "memory usage: 61.0+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "merged_data = pd.concat(data_frames, ignore_index=True)\n",
    "print(merged_data.info())\n",
    "merged_data = merged_data.dropna()\n",
    "print(merged_data.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d321ff79",
   "metadata": {},
   "source": [
    "## Define Target and Training Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1c68a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column = 'score'\n",
    "\n",
    "predictor_columns = [ 'gdp', 'family', 'health', 'freedom', 'generosity', 'corruption']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90efb69b",
   "metadata": {},
   "source": [
    "## Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dddd453c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X = merged_data[predictor_columns].values\n",
    "y = merged_data[target_column].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3efa84c",
   "metadata": {},
   "source": [
    "## Normalize data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1821d54",
   "metadata": {},
   "source": [
    "A Min-Max Scaler was used to normalize the data to a range of 0 to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22dec0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b72db49",
   "metadata": {},
   "source": [
    "## Convert data to Pythorch tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "483cf5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b900b0c2",
   "metadata": {},
   "source": [
    "## Define the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "afb52f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HappinessPredictor(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(HappinessPredictor, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 128)\n",
    "        self.bn1 = nn.BatchNorm1d(128) \n",
    "        self.dropout1 = nn.Dropout(0.2)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.bn2 = nn.BatchNorm1d(64)  \n",
    "        self.fc3 = nn.Linear(64, 32)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc4 = nn.Linear(32, 1)\n",
    "        \n",
    "        # Initialize weights using Xavier initialization\n",
    "        init.xavier_uniform_(self.fc1.weight)\n",
    "        init.xavier_uniform_(self.fc2.weight)\n",
    "        init.xavier_uniform_(self.fc3.weight)\n",
    "        init.xavier_uniform_(self.fc4.weight)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.bn1(self.fc1(x)))\n",
    "        x = self.dropout1(x)\n",
    "        x = self.relu(self.bn2(self.fc2(x)))\n",
    "        x = self.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96ebe6c",
   "metadata": {},
   "source": [
    "## Loss Funcion & Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "094e1674",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model\n",
    "input_size = X_train_tensor.shape[1]\n",
    "model = HappinessPredictor(input_size)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6afd2d7",
   "metadata": {},
   "source": [
    "## Training the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84957ef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/2000], Loss: 0.4090\n",
      "Epoch [200/2000], Loss: 0.2626\n",
      "Epoch [300/2000], Loss: 0.2139\n",
      "Epoch [400/2000], Loss: 0.1992\n",
      "Epoch [500/2000], Loss: 0.1737\n",
      "Epoch [600/2000], Loss: 0.1652\n",
      "Epoch [700/2000], Loss: 0.1680\n",
      "Epoch [800/2000], Loss: 0.1491\n",
      "Epoch [900/2000], Loss: 0.1362\n",
      "Epoch [1000/2000], Loss: 0.1323\n",
      "Epoch [1100/2000], Loss: 0.1304\n",
      "Epoch [1200/2000], Loss: 0.1232\n",
      "Epoch [1300/2000], Loss: 0.1188\n",
      "Epoch [1400/2000], Loss: 0.1187\n",
      "Epoch [1500/2000], Loss: 0.1098\n",
      "Epoch [1600/2000], Loss: 0.1018\n",
      "Epoch [1700/2000], Loss: 0.1009\n",
      "Epoch [1800/2000], Loss: 0.0957\n",
      "Epoch [1900/2000], Loss: 0.1018\n",
      "Epoch [2000/2000], Loss: 0.1065\n"
     ]
    }
   ],
   "source": [
    "num_epochs =2000\n",
    "for epoch in range(num_epochs):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X_train_tensor)\n",
    "    loss = criterion(outputs, y_train_tensor.view(-1, 1))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111a1c53",
   "metadata": {},
   "source": [
    "## Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4c2b1aa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error on Test Data: 0.2604\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_outputs = model(X_test_tensor)\n",
    "    \n",
    "mse = mean_squared_error(y_test_tensor.numpy(), test_outputs.numpy())\n",
    "print(f'Mean Squared Error on Test Data: {mse:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aaba075",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
