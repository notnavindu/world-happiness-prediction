{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b5435c8",
   "metadata": {},
   "source": [
    "# World Happiness Report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2aa9ed",
   "metadata": {},
   "source": [
    "Happiness Prediction Deep Learning Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e47a4c",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31cca4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d80ef0",
   "metadata": {},
   "source": [
    "### Create Column Mappings & Initialize Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f55713a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frames = []\n",
    "common_columns = ['country', 'rank', 'score', 'gdp', 'family', 'health', 'freedom', 'corruption', 'generosity']\n",
    "column_mapping = {\n",
    "    '2015': {\n",
    "        'Country': 'country',\n",
    "        'Happiness Rank': 'rank',\n",
    "        'Happiness Score': 'score',\n",
    "        'Economy (GDP per Capita)': 'gdp',\n",
    "        'Family': 'family',\n",
    "        'Health (Life Expectancy)': 'health',\n",
    "        'Freedom': 'freedom',\n",
    "        'Trust (Government Corruption)': 'corruption',\n",
    "        'Generosity': 'generosity'\n",
    "    },\n",
    "    '2016': {\n",
    "        'Country': 'country',\n",
    "        'Happiness Rank': 'rank',\n",
    "        'Happiness Score': 'score',\n",
    "        'Economy (GDP per Capita)': 'gdp',\n",
    "        'Family': 'family',\n",
    "        'Health (Life Expectancy)': 'health',\n",
    "        'Freedom': 'freedom',\n",
    "        'Trust (Government Corruption)': 'corruption',\n",
    "        'Generosity': 'generosity'\n",
    "    },\n",
    "    '2017': {\n",
    "        'Country':'country',\n",
    "        'Happiness.Rank':'rank',\n",
    "        'Happiness.Score':'score',\n",
    "        'Economy..GDP.per.Capita.':'gdp',\n",
    "        'Family':'family',\n",
    "        'Health..Life.Expectancy.':'health',\n",
    "        'Freedom':'freedom',\n",
    "        'Generosity':'generosity',\n",
    "        'Trust..Government.Corruption.':'corruption'\n",
    "    },\n",
    "    '2018': {\n",
    "        'Country or region':'country',\n",
    "        'Overall rank':'rank',\n",
    "        'Score':'score',\n",
    "        'GDP per capita':'gdp',\n",
    "        'Social support':'family',\n",
    "        'Healthy life expectancy':'health',\n",
    "        'Freedom to make life choices':'freedom',\n",
    "        'Generosity':'generosity',\n",
    "        'Perceptions of corruption':'corruption'\n",
    "    },\n",
    "     '2019': {\n",
    "        'Country or region':'country',\n",
    "        'Overall rank':'rank',\n",
    "        'Score':'score',\n",
    "        'GDP per capita':'gdp',\n",
    "        'Social support':'family',\n",
    "        'Healthy life expectancy':'health',\n",
    "        'Freedom to make life choices':'freedom',\n",
    "        'Generosity':'generosity',\n",
    "        'Perceptions of corruption':'corruption'\n",
    "    }\n",
    "} \n",
    "\n",
    "years = ['2015', '2016','2017','2018','2019']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd450bda",
   "metadata": {},
   "source": [
    "### Import Datasets and Map Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8fc8ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['country', 'rank', 'score', 'gdp', 'family', 'health', 'freedom', 'corruption', 'generosity']\n",
      "['country', 'rank', 'score', 'gdp', 'family', 'health', 'freedom', 'corruption', 'generosity']\n",
      "['country', 'rank', 'score', 'gdp', 'family', 'health', 'freedom', 'corruption', 'generosity']\n",
      "['country', 'rank', 'score', 'gdp', 'family', 'health', 'freedom', 'corruption', 'generosity']\n",
      "['country', 'rank', 'score', 'gdp', 'family', 'health', 'freedom', 'corruption', 'generosity']\n"
     ]
    }
   ],
   "source": [
    "for year in years:\n",
    "    file_path = f'./dataset/{year}.csv'\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Rename columns to common names\n",
    "    df.rename(columns=column_mapping[year], inplace=True)\n",
    "    \n",
    "    df = df[common_columns]\n",
    "    \n",
    "    print(list(df.head()))\n",
    "    \n",
    "    data_frames.append(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a0ceac",
   "metadata": {},
   "source": [
    "### Merge Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17c4d051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 782 entries, 0 to 781\n",
      "Data columns (total 9 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   country     782 non-null    object \n",
      " 1   rank        782 non-null    int64  \n",
      " 2   score       782 non-null    float64\n",
      " 3   gdp         782 non-null    float64\n",
      " 4   family      782 non-null    float64\n",
      " 5   health      782 non-null    float64\n",
      " 6   freedom     782 non-null    float64\n",
      " 7   corruption  781 non-null    float64\n",
      " 8   generosity  782 non-null    float64\n",
      "dtypes: float64(7), int64(1), object(1)\n",
      "memory usage: 55.1+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 781 entries, 0 to 781\n",
      "Data columns (total 9 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   country     781 non-null    object \n",
      " 1   rank        781 non-null    int64  \n",
      " 2   score       781 non-null    float64\n",
      " 3   gdp         781 non-null    float64\n",
      " 4   family      781 non-null    float64\n",
      " 5   health      781 non-null    float64\n",
      " 6   freedom     781 non-null    float64\n",
      " 7   corruption  781 non-null    float64\n",
      " 8   generosity  781 non-null    float64\n",
      "dtypes: float64(7), int64(1), object(1)\n",
      "memory usage: 61.0+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "merged_data = pd.concat(data_frames, ignore_index=True)\n",
    "print(merged_data.info())\n",
    "merged_data = merged_data.dropna()\n",
    "print(merged_data.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d321ff79",
   "metadata": {},
   "source": [
    "### Define Target and Training Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1c68a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column = 'score'\n",
    "\n",
    "predictor_columns = [ 'gdp', 'family', 'health', 'freedom', 'generosity', 'corruption']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90efb69b",
   "metadata": {},
   "source": [
    "### Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dddd453c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X = merged_data[predictor_columns].values\n",
    "y = merged_data[target_column].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6553d293",
   "metadata": {},
   "source": [
    "## Creating the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5888c7",
   "metadata": {},
   "source": [
    "### Standardize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4847fd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef28f37d",
   "metadata": {},
   "source": [
    "### Convert floats into tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "453da957",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc2c6b5",
   "metadata": {},
   "source": [
    "### Define the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86ee3286",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HappinessPredictor(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(HappinessPredictor, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f915fca0",
   "metadata": {},
   "source": [
    "### Create the Model and define the loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d6bae73",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HappinessPredictor(input_size=len(predictor_columns))\n",
    "# torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "criterion = nn.MSELoss()  # Mean Squared Error loss\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d14185",
   "metadata": {},
   "source": [
    "### Training the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af25e13f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\navan\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:530: UserWarning: Using a target size (torch.Size([624])) that is different to the input size (torch.Size([624, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/5000], Loss: 2.6765\n",
      "Epoch [200/5000], Loss: 2.0004\n",
      "Epoch [300/5000], Loss: 1.7052\n",
      "Epoch [400/5000], Loss: 1.4762\n",
      "Epoch [500/5000], Loss: 1.3362\n",
      "Epoch [600/5000], Loss: 1.2959\n",
      "Epoch [700/5000], Loss: 1.2870\n",
      "Epoch [800/5000], Loss: 1.2835\n",
      "Epoch [900/5000], Loss: 1.2817\n",
      "Epoch [1000/5000], Loss: 1.2805\n",
      "Epoch [1100/5000], Loss: 1.2797\n",
      "Epoch [1200/5000], Loss: 1.2791\n",
      "Epoch [1300/5000], Loss: 1.2785\n",
      "Epoch [1400/5000], Loss: 1.2781\n",
      "Epoch [1500/5000], Loss: 1.2778\n",
      "Epoch [1600/5000], Loss: 1.2775\n",
      "Epoch [1700/5000], Loss: 1.2772\n",
      "Epoch [1800/5000], Loss: 1.2770\n",
      "Epoch [1900/5000], Loss: 1.2768\n",
      "Epoch [2000/5000], Loss: 1.2766\n",
      "Epoch [2100/5000], Loss: 1.2764\n",
      "Epoch [2200/5000], Loss: 1.2763\n",
      "Epoch [2300/5000], Loss: 1.2762\n",
      "Epoch [2400/5000], Loss: 1.2761\n",
      "Epoch [2500/5000], Loss: 1.2760\n",
      "Epoch [2600/5000], Loss: 1.2759\n",
      "Epoch [2700/5000], Loss: 1.2758\n",
      "Epoch [2800/5000], Loss: 1.2758\n",
      "Epoch [2900/5000], Loss: 1.2757\n",
      "Epoch [3000/5000], Loss: 1.2756\n",
      "Epoch [3100/5000], Loss: 1.2756\n",
      "Epoch [3200/5000], Loss: 1.2755\n",
      "Epoch [3300/5000], Loss: 1.2755\n",
      "Epoch [3400/5000], Loss: 1.2754\n",
      "Epoch [3500/5000], Loss: 1.2754\n",
      "Epoch [3600/5000], Loss: 1.2754\n",
      "Epoch [3700/5000], Loss: 1.2753\n",
      "Epoch [3800/5000], Loss: 1.2753\n",
      "Epoch [3900/5000], Loss: 1.2753\n",
      "Epoch [4000/5000], Loss: 1.2753\n",
      "Epoch [4100/5000], Loss: 1.2752\n",
      "Epoch [4200/5000], Loss: 1.2752\n",
      "Epoch [4300/5000], Loss: 1.2752\n",
      "Epoch [4400/5000], Loss: 1.2752\n",
      "Epoch [4500/5000], Loss: 1.2752\n",
      "Epoch [4600/5000], Loss: 1.2752\n",
      "Epoch [4700/5000], Loss: 1.2751\n",
      "Epoch [4800/5000], Loss: 1.2751\n",
      "Epoch [4900/5000], Loss: 1.2751\n",
      "Epoch [5000/5000], Loss: 1.2751\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5000\n",
    "for epoch in range(num_epochs):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X_train)\n",
    "    loss = criterion(outputs, y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3356585",
   "metadata": {},
   "source": [
    "### Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "430d7a06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error on Test Data: 1.2488\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_outputs = model(X_test)\n",
    "    \n",
    "mse = mean_squared_error(y_test.numpy(), test_outputs.numpy())\n",
    "print(f'Mean Squared Error on Test Data: {mse:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c19f4b",
   "metadata": {},
   "source": [
    " 1.2551\n",
    " 1.2371"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
